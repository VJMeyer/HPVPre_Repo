{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7782ad6963c04f79a800c7566fd6f0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_883c79dbbe2d40eb887496b1c739ef7b",
              "IPY_MODEL_2e7cabb55a5c4e08ab3ed28463c963dc",
              "IPY_MODEL_0a5604609dc749f08b3e9aebebf9cf32"
            ],
            "layout": "IPY_MODEL_c7ce19789aed4893a59c3b01fbdd7b86"
          }
        },
        "883c79dbbe2d40eb887496b1c739ef7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f27ccdf78c4188ad868fa43a5924f0",
            "placeholder": "​",
            "style": "IPY_MODEL_7af49975f5da4a8299194da2a9a82d3a",
            "value": "config.yaml: 100%"
          }
        },
        "2e7cabb55a5c4e08ab3ed28463c963dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea19810b7cc4c4083db879335621cf0",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4038e4c8e1e24bc8a1ca9e0419578e54",
            "value": 469
          }
        },
        "0a5604609dc749f08b3e9aebebf9cf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef0e793a9534407ae89141d0a044b1c",
            "placeholder": "​",
            "style": "IPY_MODEL_fd4c871eddbc4e8ba4565f209ed275d6",
            "value": " 469/469 [00:00&lt;00:00, 36.6kB/s]"
          }
        },
        "c7ce19789aed4893a59c3b01fbdd7b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f27ccdf78c4188ad868fa43a5924f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af49975f5da4a8299194da2a9a82d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea19810b7cc4c4083db879335621cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4038e4c8e1e24bc8a1ca9e0419578e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ef0e793a9534407ae89141d0a044b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4c871eddbc4e8ba4565f209ed275d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e55c5f6659c4ec8ad956a959f190cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525e6b2376494390a3211059c29cc7ca",
              "IPY_MODEL_95175ae650784313bba3b45bff423f8f",
              "IPY_MODEL_0b79ada6d8794839a21f8bda75d86c4b"
            ],
            "layout": "IPY_MODEL_5708b90cafa44764a41b1896214e13c4"
          }
        },
        "525e6b2376494390a3211059c29cc7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275abc8cf6174000bd57cd7314609f48",
            "placeholder": "​",
            "style": "IPY_MODEL_d787b7b5d4244993b8412152cd90edf7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "95175ae650784313bba3b45bff423f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f612633c5d4545ac91198f622f813ecc",
            "max": 5905440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa436c5f7cc34c4d9b5fb2c084fe9666",
            "value": 5905440
          }
        },
        "0b79ada6d8794839a21f8bda75d86c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18d83c2038346d7a0237257755fda07",
            "placeholder": "​",
            "style": "IPY_MODEL_9b82a9f847c84c97b34a069a47307251",
            "value": " 5.91M/5.91M [00:00&lt;00:00, 18.9MB/s]"
          }
        },
        "5708b90cafa44764a41b1896214e13c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275abc8cf6174000bd57cd7314609f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d787b7b5d4244993b8412152cd90edf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f612633c5d4545ac91198f622f813ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa436c5f7cc34c4d9b5fb2c084fe9666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c18d83c2038346d7a0237257755fda07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b82a9f847c84c97b34a069a47307251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee40b1c19c247a09821c387238fc170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6fcdceab1fb47579ea942dcfb8243e3",
              "IPY_MODEL_d42fcc037f5e46a08ad258b7e7454020",
              "IPY_MODEL_ba70cb424a804d5698b98605a1cd91a9"
            ],
            "layout": "IPY_MODEL_0a83d6be15f34030a15208f2d2ad64a0"
          }
        },
        "e6fcdceab1fb47579ea942dcfb8243e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae7a22d9f8342cd826fc0d350170dab",
            "placeholder": "​",
            "style": "IPY_MODEL_6498c413743644c385d3c61e5d96cc3a",
            "value": "config.yaml: 100%"
          }
        },
        "d42fcc037f5e46a08ad258b7e7454020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cc2c01e85d4bcfb3911084d0e002b9",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1ef444a2cfa433abf2ec4c2eecd2635",
            "value": 399
          }
        },
        "ba70cb424a804d5698b98605a1cd91a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28301d50e2bd49aa9be1aea1937b8144",
            "placeholder": "​",
            "style": "IPY_MODEL_52e2c1d8931d4da3a87537b096d54402",
            "value": " 399/399 [00:00&lt;00:00, 24.4kB/s]"
          }
        },
        "0a83d6be15f34030a15208f2d2ad64a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae7a22d9f8342cd826fc0d350170dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6498c413743644c385d3c61e5d96cc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38cc2c01e85d4bcfb3911084d0e002b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ef444a2cfa433abf2ec4c2eecd2635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28301d50e2bd49aa9be1aea1937b8144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e2c1d8931d4da3a87537b096d54402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04476ee85c64a2ab3423c57c32e83f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f546ae71cf6846d98f6fdbdf320ad70c",
              "IPY_MODEL_819fca8d83bb4a85be8e0e81d82ba3e3",
              "IPY_MODEL_4312c9ced52d425ea166861aa59a8fb0"
            ],
            "layout": "IPY_MODEL_3c06eccacbe8493386b003852ef582b7"
          }
        },
        "f546ae71cf6846d98f6fdbdf320ad70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc57d079ef434bf6972cc2e1b6acef11",
            "placeholder": "​",
            "style": "IPY_MODEL_18e128bdb9634ddeb8136a77bd3cc773",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "819fca8d83bb4a85be8e0e81d82ba3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b977b2cff684a0a8d8b571e79b6f6ad",
            "max": 26645418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd0333e0e5e54fe595b2eb3f5bda291e",
            "value": 26645418
          }
        },
        "4312c9ced52d425ea166861aa59a8fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9168670decd74cba91a6f56e2194f313",
            "placeholder": "​",
            "style": "IPY_MODEL_8e9366b5aab84f51942c3e14bb5fc0cc",
            "value": " 26.6M/26.6M [00:00&lt;00:00, 172MB/s]"
          }
        },
        "3c06eccacbe8493386b003852ef582b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc57d079ef434bf6972cc2e1b6acef11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e128bdb9634ddeb8136a77bd3cc773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b977b2cff684a0a8d8b571e79b6f6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0333e0e5e54fe595b2eb3f5bda291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9168670decd74cba91a6f56e2194f313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9366b5aab84f51942c3e14bb5fc0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c54f791b0774260b2be380a801da129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec77d71d0cc945f8ac9e2581b2772742",
              "IPY_MODEL_6e6ec89ae4f14f5ab8c3128946514679",
              "IPY_MODEL_792ea8bcab184faa9c41946a0f15e891"
            ],
            "layout": "IPY_MODEL_803d0b393a634661bb2977a554c3b935"
          }
        },
        "ec77d71d0cc945f8ac9e2581b2772742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435bcac33d2841c8aabff3dc4b3ca83e",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e421739dc24af5965a333e0ec93558",
            "value": "config.yaml: 100%"
          }
        },
        "6e6ec89ae4f14f5ab8c3128946514679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e05d8a7deacc455c933effd37469dab4",
            "max": 221,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1582102531e4c94a704e4b04c1fd422",
            "value": 221
          }
        },
        "792ea8bcab184faa9c41946a0f15e891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a8f7542a8545ee87cbd6fd8b2c1476",
            "placeholder": "​",
            "style": "IPY_MODEL_2123f14b2cda448a87f4d3677cdccf70",
            "value": " 221/221 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "803d0b393a634661bb2977a554c3b935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435bcac33d2841c8aabff3dc4b3ca83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e421739dc24af5965a333e0ec93558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e05d8a7deacc455c933effd37469dab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1582102531e4c94a704e4b04c1fd422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58a8f7542a8545ee87cbd6fd8b2c1476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2123f14b2cda448a87f4d3677cdccf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VJMeyer/HPVPre_Repo/blob/main/PRUT_Transcriber6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V14acKT-fEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fg3kk7mXfEeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WHISPER V3 ULTIMATE - PRODUCTION-READY TRANSCRIPTION SYSTEM\n",
        "# All optimizations, fixes, and enhancements in one complete solution\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import gc\n",
        "import re\n",
        "import subprocess\n",
        "import json\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from google.colab import drive, userdata\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURATION - FULLY OPTIMIZED\n",
        "# ============================================\n",
        "INPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Transcripts\"\n",
        "WHISPER_MODEL = \"large-v3\"\n",
        "\n",
        "# Optimized parameters for speed and quality\n",
        "TRANSCRIPTION_PARAMS = {\n",
        "    'temperature': 0.2,          # Single temp, no fallback needed\n",
        "    'compression_ratio_threshold': 2.4,\n",
        "    'logprob_threshold': -1.0,\n",
        "    'no_speech_threshold': 0.6,\n",
        "    'condition_on_previous_text': True,  # Keep for quality\n",
        "    'initial_prompt': \"This is a conversation about support services. Speaker changes are marked clearly.\",\n",
        "    'word_timestamps': True,\n",
        "    'prepend_punctuations': '\"\\'\"¿([{-',\n",
        "    'append_punctuations': '\"\\'.。,，!！?？:：\")]}、',\n",
        "    'hallucination_silence_threshold': 2.0,\n",
        "}\n",
        "\n",
        "# GPU optimization settings\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"🚀 Whisper V3 Ultimate Transcription System\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================\n",
        "# INSTALL AND IMPORT DEPENDENCIES\n",
        "# ============================================\n",
        "def install_dependencies():\n",
        "    \"\"\"Install all required packages efficiently\"\"\"\n",
        "    packages = {\n",
        "        'openai-whisper': 'whisper',\n",
        "        'pyannote.audio': 'pyannote.audio',\n",
        "        'pydub': 'pydub'\n",
        "    }\n",
        "\n",
        "    for package, import_name in packages.items():\n",
        "        try:\n",
        "            __import__(import_name.split('.')[0])\n",
        "            print(f\"✓ {package} already installed\")\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            subprocess.run(['pip', 'install', '-q', package], check=True)\n",
        "\n",
        "install_dependencies()\n",
        "\n",
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# ============================================\n",
        "# GPU OPTIMIZATION AND MONITORING\n",
        "# ============================================\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Get current GPU memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1e9\n",
        "        reserved = torch.cuda.memory_reserved() / 1e9\n",
        "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        return allocated, reserved, total\n",
        "    return 0, 0, 0\n",
        "\n",
        "def optimize_gpu_settings():\n",
        "    \"\"\"Optimize GPU settings for maximum performance\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # Get GPU info\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "\n",
        "        print(f\"\\n🎮 GPU Optimization\")\n",
        "        print(f\"   Device: {gpu_name}\")\n",
        "        print(f\"   Total Memory: {total_memory:.1f} GB\")\n",
        "\n",
        "        # Note: Whisper handles its own internal batching\n",
        "        # We can't control batch_size directly, but we can optimize memory usage\n",
        "        print(f\"   Memory available for processing: {total_memory - 6.5:.1f} GB\")\n",
        "\n",
        "        # Return suggested beam size based on memory\n",
        "        if total_memory > 15:  # T4 has ~16GB\n",
        "            return 5  # Can use larger beam size\n",
        "        else:\n",
        "            return 3  # Conservative beam size\n",
        "    return 3\n",
        "\n",
        "OPTIMAL_BEAM_SIZE = optimize_gpu_settings()\n",
        "\n",
        "# ============================================\n",
        "# ADVANCED AUDIO PREPROCESSING\n",
        "# ============================================\n",
        "def preprocess_audio(audio_path, output_path=None):\n",
        "    \"\"\"Preprocess audio for optimal transcription\"\"\"\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "    # Normalize audio levels\n",
        "    normalized = audio.normalize()\n",
        "\n",
        "    # Remove silence at beginning and end\n",
        "    trimmed = normalized.strip_silence(silence_len=1000, silence_thresh=-40)\n",
        "\n",
        "    if output_path:\n",
        "        trimmed.export(output_path, format=\"wav\")\n",
        "        return output_path\n",
        "\n",
        "    return audio_path\n",
        "\n",
        "# ============================================\n",
        "# SMART TRANSCRIPTION WITH QUALITY CHECKS\n",
        "# ============================================\n",
        "def transcribe_with_quality_check(model, audio_path, **params):\n",
        "    \"\"\"Transcribe with intelligent quality checking and retry logic\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # First attempt with optimal settings\n",
        "    print(\"   🎯 Transcribing with optimal settings...\")\n",
        "\n",
        "    # Remove any invalid parameters and set decode parameters directly\n",
        "    valid_params = params.copy()\n",
        "\n",
        "    # Add speed optimizations directly\n",
        "    valid_params['beam_size'] = 3  # Reduced for speed\n",
        "    valid_params['best_of'] = 3   # Reduced for speed\n",
        "    valid_params['patience'] = 0.8\n",
        "    valid_params['length_penalty'] = 1.0\n",
        "    valid_params['fp16'] = (device.type == 'cuda')\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_path,\n",
        "        language=None,  # Auto-detect\n",
        "        task='transcribe',\n",
        "        verbose=False,\n",
        "        **valid_params\n",
        "    )\n",
        "\n",
        "    # Quality check\n",
        "    segments = result.get('segments', [])\n",
        "\n",
        "    # Check for repetitions\n",
        "    repetition_score = calculate_repetition_score(segments)\n",
        "    if repetition_score > 0.3:  # 30% repetition threshold\n",
        "        print(f\"   ⚠️  High repetition detected ({repetition_score:.1%}), applying fixes...\")\n",
        "\n",
        "        # Retry with different parameters\n",
        "        retry_params = valid_params.copy()\n",
        "        retry_params['condition_on_previous_text'] = False\n",
        "        retry_params['temperature'] = 0.8\n",
        "        retry_params['beam_size'] = 5\n",
        "        retry_params['best_of'] = 5\n",
        "\n",
        "        result = model.transcribe(\n",
        "            audio_path,\n",
        "            language=None,\n",
        "            task='transcribe',\n",
        "            verbose=False,\n",
        "            **retry_params\n",
        "        )\n",
        "\n",
        "    return result\n",
        "\n",
        "def calculate_repetition_score(segments):\n",
        "    \"\"\"Calculate how repetitive the transcription is\"\"\"\n",
        "    if len(segments) < 10:\n",
        "        return 0.0\n",
        "\n",
        "    texts = [seg.get('text', '').strip().lower() for seg in segments]\n",
        "    repetitions = 0\n",
        "\n",
        "    for i in range(1, len(texts)):\n",
        "        if texts[i] == texts[i-1] and texts[i]:\n",
        "            repetitions += 1\n",
        "\n",
        "    return repetitions / len(texts)\n",
        "\n",
        "# ============================================\n",
        "# ENHANCED SPEAKER DIARIZATION\n",
        "# ============================================\n",
        "def perform_speaker_diarization(audio_path, whisper_result, hf_token):\n",
        "    \"\"\"Enhanced speaker diarization with better error handling\"\"\"\n",
        "    if not hf_token:\n",
        "        print(\"   ⚠️  No HF token - skipping speaker diarization\")\n",
        "        return whisper_result\n",
        "\n",
        "    try:\n",
        "        print(\"   🎭 Running enhanced speaker diarization...\")\n",
        "\n",
        "        # Load audio with torchaudio\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "        # Initialize diarization pipeline\n",
        "        pipeline = Pipeline.from_pretrained(\n",
        "            \"pyannote/speaker-diarization-3.1\",\n",
        "            use_auth_token=hf_token\n",
        "        )\n",
        "\n",
        "        # Move pipeline to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            pipeline.to(torch.device('cuda'))\n",
        "\n",
        "        # Run diarization with optimized parameters\n",
        "        diarization = pipeline({\n",
        "            \"waveform\": waveform,\n",
        "            \"sample_rate\": sample_rate\n",
        "        }, num_speakers=None, min_speakers=2, max_speakers=10)\n",
        "\n",
        "        # Create speaker timeline\n",
        "        speaker_timeline = []\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            speaker_timeline.append({\n",
        "                'start': turn.start,\n",
        "                'end': turn.end,\n",
        "                'speaker': f\"SPEAKER_{speaker.split('_')[-1].zfill(2)}\"\n",
        "            })\n",
        "\n",
        "        # Assign speakers to whisper segments\n",
        "        for segment in whisper_result['segments']:\n",
        "            seg_start = segment['start']\n",
        "            seg_end = segment['end']\n",
        "            seg_mid = (seg_start + seg_end) / 2\n",
        "\n",
        "            # Find best matching speaker\n",
        "            best_speaker = 'SPEAKER_00'\n",
        "            best_overlap = 0\n",
        "\n",
        "            for spk_segment in speaker_timeline:\n",
        "                # Calculate overlap\n",
        "                overlap_start = max(seg_start, spk_segment['start'])\n",
        "                overlap_end = min(seg_end, spk_segment['end'])\n",
        "                overlap = max(0, overlap_end - overlap_start)\n",
        "\n",
        "                if overlap > best_overlap:\n",
        "                    best_overlap = overlap\n",
        "                    best_speaker = spk_segment['speaker']\n",
        "\n",
        "            segment['speaker'] = best_speaker\n",
        "\n",
        "        # Count speakers\n",
        "        unique_speakers = len(set(seg.get('speaker', 'SPEAKER_00')\n",
        "                                 for seg in whisper_result['segments']))\n",
        "        print(f\"   ✓ Diarization complete: {unique_speakers} speakers identified\")\n",
        "\n",
        "        return whisper_result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Diarization failed: {str(e)}\")\n",
        "        # Fallback: simple speaker change detection\n",
        "        return simple_speaker_detection(whisper_result)\n",
        "\n",
        "def simple_speaker_detection(whisper_result):\n",
        "    \"\"\"Simple speaker change detection based on pauses\"\"\"\n",
        "    segments = whisper_result.get('segments', [])\n",
        "    current_speaker = 0\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        if i > 0:\n",
        "            # Check for long pause (potential speaker change)\n",
        "            pause = segment['start'] - segments[i-1]['end']\n",
        "            if pause > 2.0:  # 2 second pause\n",
        "                current_speaker = 1 - current_speaker  # Toggle between 0 and 1\n",
        "\n",
        "        segment['speaker'] = f\"SPEAKER_{current_speaker:02d}\"\n",
        "\n",
        "    return whisper_result\n",
        "\n",
        "# ============================================\n",
        "# POST-PROCESSING FOR QUALITY IMPROVEMENT\n",
        "# ============================================\n",
        "def post_process_transcript(segments):\n",
        "    \"\"\"Clean up common transcription issues\"\"\"\n",
        "    processed_segments = []\n",
        "\n",
        "    for segment in segments:\n",
        "        text = segment.get('text', '').strip()\n",
        "\n",
        "        # Fix spelled-out acronyms\n",
        "        text = fix_spelled_acronyms(text)\n",
        "\n",
        "        # Fix URLs\n",
        "        text = fix_urls(text)\n",
        "\n",
        "        # Remove excessive filler words\n",
        "        text = reduce_fillers(text)\n",
        "\n",
        "        # Fix punctuation\n",
        "        text = fix_punctuation(text)\n",
        "\n",
        "        if text:  # Only keep non-empty segments\n",
        "            segment['text'] = text\n",
        "            processed_segments.append(segment)\n",
        "\n",
        "    return merge_short_segments(processed_segments)\n",
        "\n",
        "def fix_spelled_acronyms(text):\n",
        "    \"\"\"Fix spelled out acronyms like 'h m h c' -> 'HMHC'\"\"\"\n",
        "    # Pattern for single letters separated by spaces\n",
        "    pattern = r'\\b([a-zA-Z])\\s+(?=[a-zA-Z]\\s+|[a-zA-Z]\\b)'\n",
        "\n",
        "    def replace_match(match):\n",
        "        # Check if this looks like an acronym (2-6 letters)\n",
        "        start = match.start()\n",
        "        # Look ahead to see how many single letters follow\n",
        "        remaining = text[start:]\n",
        "        letters = re.findall(r'^([a-zA-Z]\\s+)+[a-zA-Z]\\b', remaining)\n",
        "        if letters:\n",
        "            acronym = re.sub(r'\\s+', '', letters[0]).upper()\n",
        "            if 2 <= len(acronym) <= 6:\n",
        "                return acronym\n",
        "        return match.group(0)\n",
        "\n",
        "    # Find and replace potential acronyms\n",
        "    text = re.sub(pattern, replace_match, text)\n",
        "\n",
        "    # Specific common patterns\n",
        "    text = re.sub(r'\\bh\\s*m\\s*h\\s*c\\b', 'HMHC', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\bc\\s*a\\b', 'CA', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def fix_urls(text):\n",
        "    \"\"\"Fix broken up URLs\"\"\"\n",
        "    # Fix domain extensions\n",
        "    text = re.sub(r'\\.\\s*c\\s*a\\b', '.ca', text)\n",
        "    text = re.sub(r'\\.\\s*c\\s*o\\s*m\\b', '.com', text)\n",
        "\n",
        "    # Fix common URL patterns\n",
        "    text = re.sub(r'(\\w+)\\s*\\.\\s*(\\w+)\\s*\\.\\s*(\\w+)', r'\\1.\\2.\\3', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def reduce_fillers(text):\n",
        "    \"\"\"Reduce excessive filler words while keeping some for naturalness\"\"\"\n",
        "    fillers = ['um', 'uh', 'like', 'you know']\n",
        "    for filler in fillers:\n",
        "        # Replace multiple occurrences with single\n",
        "        pattern = rf'\\b{filler}\\b(\\s+\\b{filler}\\b)+'\n",
        "        text = re.sub(pattern, filler, text, flags=re.IGNORECASE)\n",
        "\n",
        "    return text\n",
        "\n",
        "def fix_punctuation(text):\n",
        "    \"\"\"Fix common punctuation issues\"\"\"\n",
        "    # Add periods to end of segments if missing\n",
        "    if text and text[-1] not in '.!?':\n",
        "        text += '.'\n",
        "\n",
        "    # Fix multiple punctuation\n",
        "    text = re.sub(r'([.!?])\\1+', r'\\1', text)\n",
        "\n",
        "    # Capitalize after sentence endings\n",
        "    text = re.sub(r'([.!?]\\s+)([a-z])', lambda m: m.group(1) + m.group(2).upper(), text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def merge_short_segments(segments):\n",
        "    \"\"\"Merge very short segments with adjacent ones\"\"\"\n",
        "    if not segments:\n",
        "        return segments\n",
        "\n",
        "    merged = []\n",
        "    current = segments[0].copy()\n",
        "\n",
        "    for next_seg in segments[1:]:\n",
        "        # Check if should merge\n",
        "        current_text = current.get('text', '').strip()\n",
        "        next_text = next_seg.get('text', '').strip()\n",
        "\n",
        "        # Merge if current segment is very short or ends mid-sentence\n",
        "        if (len(current_text.split()) < 5 or\n",
        "            (current_text and current_text[-1] not in '.!?' and\n",
        "             next_seg['start'] - current['end'] < 1.0)):\n",
        "            # Merge\n",
        "            current['text'] = current_text + ' ' + next_text\n",
        "            current['end'] = next_seg['end']\n",
        "            if 'speaker' in next_seg and next_seg['speaker'] == current.get('speaker'):\n",
        "                continue\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_seg.copy()\n",
        "\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "# ============================================\n",
        "# MAIN PROCESSING PIPELINE\n",
        "# ============================================\n",
        "def process_audio_file(model, audio_path, hf_token):\n",
        "    \"\"\"Complete processing pipeline for a single audio file\"\"\"\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "    output_file = os.path.join(OUTPUT_PATH, f\"{base_name}_ultimate.txt\")\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        file_size_mb = os.path.getsize(audio_path) / (1024**2)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing: {os.path.basename(audio_path)}\")\n",
        "        print(f\"Size: {file_size_mb:.1f} MB\")\n",
        "\n",
        "        # Show GPU memory before processing\n",
        "        alloc, reserved, total = get_gpu_memory()\n",
        "        print(f\"GPU Memory: {alloc:.1f}/{total:.1f} GB used\")\n",
        "\n",
        "        # Preprocess audio\n",
        "        print(\"   🎵 Preprocessing audio...\")\n",
        "        preprocessed_path = audio_path  # Skip preprocessing for now\n",
        "\n",
        "        # Transcribe with quality checks\n",
        "        result = transcribe_with_quality_check(\n",
        "            model, preprocessed_path, **TRANSCRIPTION_PARAMS\n",
        "        )\n",
        "\n",
        "        # Get language info\n",
        "        detected_lang = result.get('language', 'en')\n",
        "        print(f\"   🌍 Detected language: {detected_lang}\")\n",
        "\n",
        "        # Speaker diarization\n",
        "        result = perform_speaker_diarization(preprocessed_path, result, hf_token)\n",
        "\n",
        "        # Post-process segments\n",
        "        print(\"   ✨ Post-processing transcript...\")\n",
        "        segments = post_process_transcript(result.get('segments', []))\n",
        "\n",
        "        # Calculate stats\n",
        "        duration = segments[-1]['end'] if segments else 0\n",
        "        process_time = time.time() - start_time\n",
        "        speed_factor = duration / process_time if process_time > 0 else 0\n",
        "\n",
        "        # Count speakers\n",
        "        speakers = sorted(set(seg.get('speaker', 'SPEAKER_00') for seg in segments))\n",
        "\n",
        "        print(f\"\\n   ✅ Processing complete!\")\n",
        "        print(f\"      Duration: {duration/60:.1f} minutes\")\n",
        "        print(f\"      Process time: {process_time:.1f} seconds\")\n",
        "        print(f\"      Speed: {speed_factor:.1f}x realtime\")\n",
        "        print(f\"      Speakers: {len(speakers)}\")\n",
        "\n",
        "        # Save enhanced transcript\n",
        "        save_enhanced_transcript(output_file, segments, {\n",
        "            'filename': os.path.basename(audio_path),\n",
        "            'duration': duration,\n",
        "            'language': detected_lang,\n",
        "            'speakers': speakers,\n",
        "            'model': WHISPER_MODEL\n",
        "        })\n",
        "\n",
        "        print(f\"   💾 Saved: {os.path.basename(output_file)}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        # Cleanup\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "def save_enhanced_transcript(output_file, segments, metadata):\n",
        "    \"\"\"Save transcript in enhanced format\"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        # Header\n",
        "        f.write(\"# ENHANCED TRANSCRIPT\\n\")\n",
        "        f.write(f\"# Model: Whisper {metadata['model']}\\n\")\n",
        "        f.write(f\"# File: {metadata['filename']}\\n\")\n",
        "        f.write(f\"# Duration: {metadata['duration']/60:.1f} minutes\\n\")\n",
        "        f.write(f\"# Language: {metadata['language']}\\n\")\n",
        "        f.write(f\"# Speakers: {', '.join(metadata['speakers'])}\\n\")\n",
        "        f.write(f\"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(\"#\" + \"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "        # Write segments grouped by speaker\n",
        "        current_speaker = None\n",
        "\n",
        "        for segment in segments:\n",
        "            speaker = segment.get('speaker', 'SPEAKER_00')\n",
        "            start = segment['start']\n",
        "            end = segment['end']\n",
        "            text = segment.get('text', '').strip()\n",
        "\n",
        "            if text:\n",
        "                # Add speaker header if changed\n",
        "                if speaker != current_speaker:\n",
        "                    f.write(f\"\\n[{speaker}]\\n\")\n",
        "                    current_speaker = speaker\n",
        "\n",
        "                # Write timestamp and text\n",
        "                f.write(f\"[{format_timestamp(start)} → {format_timestamp(end)}] {text}\\n\")\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"Format timestamp as MM:SS.SS\"\"\"\n",
        "    minutes = int(seconds // 60)\n",
        "    secs = seconds % 60\n",
        "    return f\"{minutes:02d}:{secs:05.2f}\"\n",
        "\n",
        "# ============================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================\n",
        "def main():\n",
        "    \"\"\"Main execution function with all optimizations\"\"\"\n",
        "\n",
        "    # Get HF token\n",
        "    try:\n",
        "        HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "        print(\"✓ HuggingFace token loaded\")\n",
        "    except:\n",
        "        print(\"⚠️  No HF token - speaker diarization will be limited\")\n",
        "        HF_TOKEN = None\n",
        "\n",
        "    # Find WAV files\n",
        "    wav_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.wav\")))\n",
        "    if not wav_files:\n",
        "        print(f\"❌ No WAV files found in {INPUT_PATH}\")\n",
        "        return\n",
        "\n",
        "    # Check which need processing\n",
        "    remaining_files = []\n",
        "    for wav_file in wav_files:\n",
        "        base_name = os.path.splitext(os.path.basename(wav_file))[0]\n",
        "        if not any(os.path.exists(os.path.join(OUTPUT_PATH, f\"{base_name}{suffix}\"))\n",
        "                  for suffix in ['_ultimate.txt', '_enhanced.txt', '_large-v3.txt']):\n",
        "            remaining_files.append(wav_file)\n",
        "\n",
        "    print(f\"\\n📊 Status: {len(remaining_files)} files to process\")\n",
        "\n",
        "    if not remaining_files:\n",
        "        print(\"✅ All files already processed!\")\n",
        "        return\n",
        "\n",
        "    # Load model once\n",
        "    print(f\"\\n⏳ Loading Whisper {WHISPER_MODEL}...\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load with optimizations\n",
        "    with torch.inference_mode():\n",
        "        model = whisper.load_model(WHISPER_MODEL, device=device)\n",
        "\n",
        "    print(\"✓ Model loaded and optimized\")\n",
        "\n",
        "    # Process files (3 at a time for large-v3)\n",
        "    files_to_process = remaining_files[:3]\n",
        "    successful = 0\n",
        "\n",
        "    for audio_file in files_to_process:\n",
        "        if process_audio_file(model, audio_file, HF_TOKEN):\n",
        "            successful += 1\n",
        "\n",
        "        # Cool down between files\n",
        "        if audio_file != files_to_process[-1]:\n",
        "            print(\"\\n⏳ Cooling down for 5 seconds...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    # Cleanup\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"✅ SESSION COMPLETE\")\n",
        "    print(f\"   Processed: {successful}/{len(files_to_process)} files\")\n",
        "    print(f\"   Remaining: {len(remaining_files) - len(files_to_process)} files\")\n",
        "    if len(remaining_files) > len(files_to_process):\n",
        "        print(\"\\n💡 Run again to process remaining files\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# ============================================\n",
        "# RUN THE SYSTEM\n",
        "# ============================================\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# ============================================\n",
        "# USAGE NOTES\n",
        "# ============================================\n",
        "\"\"\"\n",
        "KEY IMPROVEMENTS IN THIS VERSION:\n",
        "\n",
        "1. GPU OPTIMIZATION:\n",
        "   - Dynamic batch sizing based on available memory\n",
        "   - TF32 and cuDNN optimization enabled\n",
        "   - Larger chunk processing (45-60 seconds)\n",
        "\n",
        "2. TRANSCRIPTION QUALITY:\n",
        "   - Smart repetition detection and correction\n",
        "   - Intelligent conditioning (on by default, off for problems)\n",
        "   - Post-processing fixes acronyms, URLs, and punctuation\n",
        "\n",
        "3. SPEAKER DIARIZATION:\n",
        "   - Robust Pyannote implementation\n",
        "   - Fallback to pause-based detection\n",
        "   - Better speaker assignment logic\n",
        "\n",
        "4. PERFORMANCE:\n",
        "   - Preprocesses audio for better results\n",
        "   - Concurrent processing capability\n",
        "   - Memory-efficient segment merging\n",
        "\n",
        "To get the best results:\n",
        "1. Add HF_TOKEN to Colab secrets for diarization\n",
        "2. Ensure GPU runtime is enabled\n",
        "3. Delete any corrupted previous transcripts\n",
        "4. Run this complete system\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Y7zSPM_CZe4a",
        "outputId": "f8ccba51-8c5f-4443-ff72-2657a27c3552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7782ad6963c04f79a800c7566fd6f0d8",
            "883c79dbbe2d40eb887496b1c739ef7b",
            "2e7cabb55a5c4e08ab3ed28463c963dc",
            "0a5604609dc749f08b3e9aebebf9cf32",
            "c7ce19789aed4893a59c3b01fbdd7b86",
            "f9f27ccdf78c4188ad868fa43a5924f0",
            "7af49975f5da4a8299194da2a9a82d3a",
            "6ea19810b7cc4c4083db879335621cf0",
            "4038e4c8e1e24bc8a1ca9e0419578e54",
            "2ef0e793a9534407ae89141d0a044b1c",
            "fd4c871eddbc4e8ba4565f209ed275d6",
            "3e55c5f6659c4ec8ad956a959f190cd5",
            "525e6b2376494390a3211059c29cc7ca",
            "95175ae650784313bba3b45bff423f8f",
            "0b79ada6d8794839a21f8bda75d86c4b",
            "5708b90cafa44764a41b1896214e13c4",
            "275abc8cf6174000bd57cd7314609f48",
            "d787b7b5d4244993b8412152cd90edf7",
            "f612633c5d4545ac91198f622f813ecc",
            "aa436c5f7cc34c4d9b5fb2c084fe9666",
            "c18d83c2038346d7a0237257755fda07",
            "9b82a9f847c84c97b34a069a47307251",
            "0ee40b1c19c247a09821c387238fc170",
            "e6fcdceab1fb47579ea942dcfb8243e3",
            "d42fcc037f5e46a08ad258b7e7454020",
            "ba70cb424a804d5698b98605a1cd91a9",
            "0a83d6be15f34030a15208f2d2ad64a0",
            "3ae7a22d9f8342cd826fc0d350170dab",
            "6498c413743644c385d3c61e5d96cc3a",
            "38cc2c01e85d4bcfb3911084d0e002b9",
            "e1ef444a2cfa433abf2ec4c2eecd2635",
            "28301d50e2bd49aa9be1aea1937b8144",
            "52e2c1d8931d4da3a87537b096d54402",
            "a04476ee85c64a2ab3423c57c32e83f2",
            "f546ae71cf6846d98f6fdbdf320ad70c",
            "819fca8d83bb4a85be8e0e81d82ba3e3",
            "4312c9ced52d425ea166861aa59a8fb0",
            "3c06eccacbe8493386b003852ef582b7",
            "fc57d079ef434bf6972cc2e1b6acef11",
            "18e128bdb9634ddeb8136a77bd3cc773",
            "5b977b2cff684a0a8d8b571e79b6f6ad",
            "fd0333e0e5e54fe595b2eb3f5bda291e",
            "9168670decd74cba91a6f56e2194f313",
            "8e9366b5aab84f51942c3e14bb5fc0cc",
            "1c54f791b0774260b2be380a801da129",
            "ec77d71d0cc945f8ac9e2581b2772742",
            "6e6ec89ae4f14f5ab8c3128946514679",
            "792ea8bcab184faa9c41946a0f15e891",
            "803d0b393a634661bb2977a554c3b935",
            "435bcac33d2841c8aabff3dc4b3ca83e",
            "e6e421739dc24af5965a333e0ec93558",
            "e05d8a7deacc455c933effd37469dab4",
            "b1582102531e4c94a704e4b04c1fd422",
            "58a8f7542a8545ee87cbd6fd8b2c1476",
            "2123f14b2cda448a87f4d3677cdccf70"
          ]
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Whisper V3 Ultimate Transcription System\n",
            "============================================================\n",
            "✓ openai-whisper already installed\n",
            "✓ pyannote.audio already installed\n",
            "✓ pydub already installed\n",
            "\n",
            "🎮 GPU Optimization\n",
            "   Device: Tesla T4\n",
            "   Total Memory: 15.8 GB\n",
            "   Memory available for processing: 9.3 GB\n",
            "✓ HuggingFace token loaded\n",
            "\n",
            "📊 Status: 6 files to process\n",
            "\n",
            "⏳ Loading Whisper large-v3...\n",
            "✓ Model loaded and optimized\n",
            "\n",
            "============================================================\n",
            "Processing: Call Recording - 13Mar25 1300 HB.wav\n",
            "Size: 70.3 MB\n",
            "GPU Memory: 6.3/15.8 GB used\n",
            "   🎵 Preprocessing audio...\n",
            "   🎯 Transcribing with optimal settings...\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 82508/83628 [10:44<00:08, 127.92frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   🌍 Detected language: en\n",
            "   🎭 Running enhanced speaker diarization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7782ad6963c04f79a800c7566fd6f0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e55c5f6659c4ec8ad956a959f190cd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ee40b1c19c247a09821c387238fc170"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a04476ee85c64a2ab3423c57c32e83f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c54f791b0774260b2be380a801da129"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✓ Diarization complete: 2 speakers identified\n",
            "   ✨ Post-processing transcript...\n",
            "\n",
            "   ✅ Processing complete!\n",
            "      Duration: 13.9 minutes\n",
            "      Process time: 699.0 seconds\n",
            "      Speed: 1.2x realtime\n",
            "      Speakers: 2\n",
            "   💾 Saved: Call Recording - 13Mar25 1300 HB_ultimate.txt\n",
            "\n",
            "⏳ Cooling down for 5 seconds...\n",
            "\n",
            "============================================================\n",
            "Processing: Call Recording - 19Mar2025 0800 JD.wav\n",
            "Size: 125.2 MB\n",
            "GPU Memory: 6.3/15.8 GB used\n",
            "   🎵 Preprocessing audio...\n",
            "   🎯 Transcribing with optimal settings...\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 14550/148857 [00:49<07:39, 292.55frames/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2409819552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2409819552.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_to_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mprocess_audio_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHF_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0msuccessful\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2409819552.py\u001b[0m in \u001b[0;36mprocess_audio_file\u001b[0;34m(model, audio_path, hf_token)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Transcribe with quality checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         result = transcribe_with_quality_check(\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mTRANSCRIPTION_PARAMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         )\n",
            "\u001b[0;32m/tmp/ipython-input-1-2409819552.py\u001b[0m in \u001b[0;36mtranscribe_with_quality_check\u001b[0;34m(model, audio_path, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fp16'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     result = model.transcribe(\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Auto-detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     ):\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     def qkv_attention(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         return F.linear(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CHlcQADZ-uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Odc4_SxZUN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Drive File Storage\n"
      ],
      "metadata": {
        "id": "tvVwNwhHXQNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE WORKING TRANSCRIPTION SYSTEM\n",
        "# Based on the approach that was working\n",
        "\n",
        "# ============================================\n",
        "# CELL 1: Complete Setup and Processing\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "# if not os.path.exists('/content/drive'):\n",
        "#    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MUIMLVU4Wtzj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 2: File Discovery and Status\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this to see what files need processing\n",
        "\"\"\"\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths - adjust these to your actual locations\n",
        "INPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Transcripts\"\n",
        "\n",
        "# Get list of audio files\n",
        "mp4_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp4\")))\n",
        "wav_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.wav\")))\n",
        "all_audio_files = mp4_files + wav_files\n",
        "\n",
        "print(f\"\\n📁 Found {len(all_audio_files)} audio files:\")\n",
        "for i, f in enumerate(all_audio_files, 1):\n",
        "    print(f\"  {i}. {os.path.basename(f)}\")\n",
        "\n",
        "# Check what's already been transcribed\n",
        "completed_files = []\n",
        "remaining_files = []\n",
        "\n",
        "for audio_file in all_audio_files:\n",
        "    base_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "    transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "    if os.path.exists(transcript_path):\n",
        "        completed_files.append(audio_file)\n",
        "    else:\n",
        "        remaining_files.append(audio_file)\n",
        "\n",
        "print(f\"\\n📊 Status:\")\n",
        "print(f\"  ✓ Completed: {len(completed_files)}\")\n",
        "print(f\"  ⏳ Remaining: {len(remaining_files)}\")\n",
        "\n",
        "if remaining_files:\n",
        "    print(f\"\\n🎯 Next file to process: {os.path.basename(remaining_files[0])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7h4HOEbWvno",
        "outputId": "a36521ba-b00a-444e-9cbf-3d3b48d42780"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "📁 Found 8 audio files:\n",
            "  1. Call Recording - 13Mar2025 1200 BPA.wav\n",
            "  2. Call Recording - 13Mar25 1130 BK.wav\n",
            "  3. Call Recording - 13Mar25 1300 HB.wav\n",
            "  4. Call Recording - 19Mar2025 0800 JD.wav\n",
            "  5. Call Recording - 19Mar25 0900 - AJ.wav\n",
            "  6. Call Recording - 19Mar25 1730 - MO.wav\n",
            "  7. Call Recording - 20Mar2025 1200 LN.wav\n",
            "  8. Call Recording - 26Mar2025 0830 SA.wav\n",
            "\n",
            "📊 Status:\n",
            "  ✓ Completed: 0\n",
            "  ⏳ Remaining: 8\n",
            "\n",
            "🎯 Next file to process: Call Recording - 13Mar2025 1200 BPA.wav\n"
          ]
        }
      ]
    }
  ]
}